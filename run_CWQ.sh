# basic NSM model
#CUDA_VISIBLE_DEVICES=0 python main_nsm.py --name CWQ --model_name gnn --data_folder /home/hegaole/data/KBQA/Freebase/CWQ/ --checkpoint_dir checkpoint/pretrain/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 300 --kg_dim 100 --kge_dim 100 --eval_every 2 --experiment_name CWQ_nsm --eps 0.95 --num_epoch 100 --use_self_loop --lr 5e-4 --q_type seq --word_emb_file word_emb_300d.npy --reason_kb --encode_type --loss_type kl
# 46.02 origin / 47.15
CUDA_VISIBLE_DEVICES=7 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 300 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 5e-4 --q_type seq --word_emb_file word_emb_300d.npy --reason_kb --encode_type --loss_type kl --experiment_name CWQ_1 1>./logs/CWQ_1.log 2>&1 &
# 45
CUDA_VISIBLE_DEVICES=2 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 300 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 5e-4 --q_type seq --word_emb_file word_emb_300d.npy --reason_kb --encode_type --loss_type kl --filter --early_stop_patience 30 --experiment_name CWQ_1_1 1>./logs/CWQ_1_1.log 2>&1 &
# 迁移原始模型的推理部分
CUDA_VISIBLE_DEVICES=4 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 3 --entity_dim 50 --word_dim 300 --kg_dim 100 --kge_dim 100 --eval_every 2 --encode_type --eps 0.95 --num_epoch 100 --use_self_loop --lr 5e-4 --word_emb_file word_emb_300d.npy --loss_type kl --reason_kb --question_encoder lstm --filter --finetune --ckpt_4_embedding CWQ_1_1-h1.ckpt --ckpt_4_pretrain CFQ_12-7.ckpt --finetune_only_reasoning --experiment_name CWQ_fine_28 1>./logs/CWQ_fine_28.log 2>&1 &

# 46.9
#CUDA_VISIBLE_DEVICES=6 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 5e-4 --q_type seq --word_emb_file word_emb_300d.npy --reason_kb --encode_type --loss_type kl --question_encoder lm --experiment_name CWQ_2 1>./logs/CWQ_2.log 2>&1 &

# 45.79
# bert编码问题
#CUDA_VISIBLE_DEVICES=0 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --experiment_name CWQ_3 1>./logs/CWQ_3.log 2>&1 &
# 45.11
# bert编码问题并更新最后一层
#CUDA_VISIBLE_DEVICES=1 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --experiment_name CWQ_4 1>./logs/CWQ_4.log 2>&1 &

# bert编码关系并更新 47.01
CUDA_VISIBLE_DEVICES=0 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy"  --experiment_name CWQ_6 1>./logs/CWQ_6.log 2>&1 &
# 固定关系 44.77
CUDA_VISIBLE_DEVICES=1 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --early_stop_patience 30 --experiment_name CWQ_7 1>./logs/CWQ_7.log 2>&1 &
# 重新跑一次 47.24
#CUDA_VISIBLE_DEVICES=7 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --early_stop_patience 30 --continue_training --load_experiment CWQ_7_1-h1.ckpt --experiment_name CWQ_7_1 1>./logs/CWQ_7_1.log 2>&1 &
#CUDA_VISIBLE_DEVICES=1 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --early_stop_patience 30 --continue_training --load_experiment CWQ_7_1-h1.ckpt --experiment_name CWQ_7_1_continue 1>./logs/CWQ_7_1_continue.log 2>&1 &
CUDA_VISIBLE_DEVICES=7 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --early_stop_patience 30 --experiment_name CWQ_7_2 1>./logs/CWQ_7_2.log 2>&1 &


# 固定关系 46.81
CUDA_VISIBLE_DEVICES=2 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --reason_with_same_param --early_stop_patience 30 --experiment_name CWQ_8 1>./logs/CWQ_8.log 2>&1 &
# 共享推理层
CUDA_VISIBLE_DEVICES=1 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --reason_with_same_param --early_stop_patience 30 --experiment_name CWQ_8_1 1>./logs/CWQ_8_1.log 2>&1 &
#CUDA_VISIBLE_DEVICES=1 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --reason_with_same_param --early_stop_patience 30 --continue_training --load_experiment CWQ_8_1-h1.ckpt --experiment_name CWQ_8_1_continue 1>./logs/CWQ_8_1_continue.log 2>&1 &


# 增加特定的关系向量 47.01
CUDA_VISIBLE_DEVICES=1 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 768 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --add_new_relation_embedding --early_stop_patience 30 --experiment_name CWQ_9 1>./logs/CWQ_9.log 2>&1 &

#CUDA_VISIBLE_DEVICES=0 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_7-h1.ckpt --ckpt_4_pretrain CFQ_1-11.ckpt --finetune_whole --early_stop_patience 30 --experiment_name CWQ_finetune_1 1>./logs/CWQ_finetune_1.log 2>&1 &
# 43.78
CUDA_VISIBLE_DEVICES=0 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_7-h1.ckpt --ckpt_4_pretrain CFQ_1-11.ckpt --finetune_whole --early_stop_patience 30 --experiment_name CWQ_finetune_2 1>./logs/CWQ_finetune_2.log 2>&1 &
# 迁移所有部分 47.98
CUDA_VISIBLE_DEVICES=1 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder ~/work/QA/KBQA/datasets/CWQ/ --checkpoint_dir ~/work/QA/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 200 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_7-h1.ckpt --ckpt_4_pretrain CFQ_2-11.ckpt --finetune_whole --early_stop_patience 30 --experiment_name CWQ_finetune_12 1>./logs/CWQ_finetune_12.log 2>&1 &
# 大batch epoch-7 47.81
CUDA_VISIBLE_DEVICES=0 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder ~/work/QA/KBQA/datasets/CWQ/ --checkpoint_dir ~/work/QA/KBQA/checkpoint/ --batch_size 80 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 200 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_7-h1.ckpt --ckpt_4_pretrain CFQ_2-7.ckpt --finetune_whole --early_stop_patience 30 --experiment_name CWQ_finetune_12_1 1>./logs/CWQ_finetune_12_1.log 2>&1 &
# 大batch epoch-11
CUDA_VISIBLE_DEVICES=1 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder ~/work/QA/KBQA/datasets/CWQ/ --checkpoint_dir ~/work/QA/KBQA/checkpoint/ --batch_size 80 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 200 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_7-h1.ckpt --ckpt_4_pretrain CFQ_2-11.ckpt --finetune_whole --early_stop_patience 30 --experiment_name CWQ_finetune_12_2 1>./logs/CWQ_finetune_12_2.log 2>&1 &
# 大batch学习率衰减
CUDA_VISIBLE_DEVICES=4 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_7-h1.ckpt --ckpt_4_pretrain CFQ_2-7.ckpt --finetune_whole --early_stop_patience 30 --merge_lr --fintune_param_lr 1e-4 --scratch_param_lr 1e-3 --scheduler_method ExponentialLR --decay_rate 0.97 --experiment_name CWQ_finetune_12_3 1>./logs/CWQ_finetune_12_3.log 2>&1 &

# 47.66
CUDA_VISIBLE_DEVICES=1 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder ~/work/QA/KBQA/datasets/CWQ/ --checkpoint_dir ~/work/QA/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 200 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_7-h1.ckpt --ckpt_4_pretrain CFQ_2-6.ckpt --finetune_whole --early_stop_patience 30 --experiment_name CWQ_finetune_13 1>./logs/CWQ_finetune_13.log 2>&1 &
# 46.98
CUDA_VISIBLE_DEVICES=1 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 40 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 200 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_7-h1.ckpt --ckpt_4_pretrain CFQ_2-6.ckpt --finetune_whole --early_stop_patience 35 --experiment_name CWQ_finetune_14 1>./logs/CWQ_finetune_14.log 2>&1 &


# 以下都是直接迁移
# 46.05
CUDA_VISIBLE_DEVICES=0 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --reason_with_same_param --ckpt_4_embedding CWQ_8-h1.ckpt --ckpt_4_pretrain CFQ_3-11.ckpt --finetune_whole --early_stop_patience 30 --experiment_name CWQ_finetune_3 1>./logs/CWQ_finetune_3.log 2>&1 &
# 45.74
CUDA_VISIBLE_DEVICES=2 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 200 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --reason_with_same_param --ckpt_4_embedding CWQ_8-h1.ckpt --ckpt_4_pretrain CFQ_3-11.ckpt --finetune_whole --early_stop_patience 30 --experiment_name CWQ_finetune_11 1>./logs/CWQ_finetune_11.log 2>&1 &
# 45.51
CUDA_VISIBLE_DEVICES=1 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 200 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --reason_with_same_param --ckpt_4_embedding CWQ_8-h1.ckpt --ckpt_4_pretrain CFQ_3-7.ckpt --finetune_whole --early_stop_patience 30 --experiment_name CWQ_finetune_6 1>./logs/CWQ_finetune_6.log 2>&1 &
# 43.47
CUDA_VISIBLE_DEVICES=1 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 200 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --reason_with_same_param --ckpt_4_embedding CWQ_8-h1.ckpt --ckpt_4_pretrain CFQ_3-3.ckpt --finetune_whole --early_stop_patience 30 --experiment_name CWQ_finetune_7 1>./logs/CWQ_finetune_7.log 2>&1 &
# 45.74
#CUDA_VISIBLE_DEVICES=2 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 200 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --reason_with_same_param --ckpt_4_embedding CWQ_8-h1.ckpt --ckpt_4_pretrain CFQ_3-11.ckpt --finetune_whole --early_stop_patience 35 --continue_training --load_experiment CWQ_finetune_11-h1.ckpt --experiment_name CWQ_finetune_11_continue 1>./logs/CWQ_finetune_11_continue.log 2>&1 &
#CUDA_VISIBLE_DEVICES=1 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 200 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --reason_with_same_param --ckpt_4_embedding CWQ_8-h1.ckpt --ckpt_4_pretrain CFQ_3-7.ckpt --finetune_whole --early_stop_patience 30 --continue_training --load_experiment CWQ_finetune_6-h1.ckpt --experiment_name CWQ_finetune_6_continue 1>./logs/CWQ_finetune_6_continue.log 2>&1 &
#CUDA_VISIBLE_DEVICES=1 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 200 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --reason_with_same_param --ckpt_4_embedding CWQ_8-h1.ckpt --ckpt_4_pretrain CFQ_3-3.ckpt --finetune_whole --early_stop_patience 30 --continue_training --load_experiment CWQ_finetune_7-h1.ckpt --experiment_name CWQ_finetune_7_continue 1>./logs/CWQ_finetune_7_continue.log 2>&1 &

# 43.22
#CUDA_VISIBLE_DEVICES=0 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_8-h1.ckpt --ckpt_4_pretrain CFQ_3-11.ckpt --finetune_reasoning --early_stop_patience 30 --experiment_name CWQ_finetune_4 1>./logs/CWQ_finetune_4.log 2>&1 &
#CUDA_VISIBLE_DEVICES=1 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder ~/work/QA/KBQA/datasets/CWQ/ --checkpoint_dir ~/work/QA/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_8-h1.ckpt --ckpt_4_pretrain CFQ_3-11.ckpt --finetune_reasoning --early_stop_patience 30 --experiment_name CWQ_finetune_4 1>./logs/CWQ_finetune_4.log 2>&1 &
#CUDA_VISIBLE_DEVICES=1 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder ~/work/QA/KBQA/datasets/CWQ/ --checkpoint_dir ~/work/QA/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_8-h1.ckpt --ckpt_4_pretrain CFQ_3-11.ckpt --finetune_instruction --early_stop_patience 30 --experiment_name CWQ_finetune_5 1>./logs/CWQ_finetune_5.log 2>&1 &
# 加载推理部分
# 44.52
CUDA_VISIBLE_DEVICES=0 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder ~/work/QA/KBQA/datasets/CWQ/ --checkpoint_dir ~/work/QA/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_8-h1.ckpt --ckpt_4_pretrain CFQ_2-11.ckpt --finetune_reasoning --early_stop_patience 30 --experiment_name CWQ_finetune_9 1>./logs/CWQ_finetune_9.log 2>&1 &
# 45.54
CUDA_VISIBLE_DEVICES=5 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 40 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 200 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_8-h1.ckpt --ckpt_4_pretrain CFQ_2-7.ckpt --finetune_reasoning --early_stop_patience 30 --experiment_name CWQ_finetune_15 1>./logs/CWQ_finetune_15.log 2>&1 &
# 相同学习率大batch 40.98
CUDA_VISIBLE_DEVICES=5 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 1e-3 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_7-h1.ckpt --ckpt_4_pretrain CFQ_2-7.ckpt --finetune --finetune_reasoning --early_stop_patience 30 --scheduler_method ExponentialLR --decay_rate 0.97 --experiment_name CWQ_finetune_15_1 1>./logs/CWQ_finetune_15_1.log 2>&1 &
# 不同学习率大batch 45.31
CUDA_VISIBLE_DEVICES=4 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_7-h1.ckpt --ckpt_4_pretrain CFQ_2-7.ckpt --finetune --finetune_reasoning --early_stop_patience 30 --merge_lr --fintune_param_lr 1e-4 --scratch_param_lr 1e-3 --scheduler_method ExponentialLR --decay_rate 0.97 --experiment_name CWQ_finetune_15_2 1>./logs/CWQ_finetune_15_2.log 2>&1 &
CUDA_VISIBLE_DEVICES=0 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder ~/work/QA/KBQA/datasets/CWQ/ --checkpoint_dir ~/work/QA/KBQA/checkpoint/ --batch_size 80 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_7-h1.ckpt --ckpt_4_pretrain CFQ_4-5.ckpt --finetune --finetune_reasoning --early_stop_patience 25 --merge_lr --fintune_param_lr 1e-4 --scratch_param_lr 1e-3 --scheduler_method ExponentialLR --decay_rate 0.97 --experiment_name CWQ_finetune_17 1>./logs/CWQ_finetune_17.log 2>&1 &


#CUDA_VISIBLE_DEVICES=4 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 40 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 200 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_8-h1.ckpt --ckpt_4_pretrain CFQ_2-7.ckpt --finetune_reasoning --early_stop_patience 30 --continue_training --load_experiment CWQ_finetune_15-h1.ckpt --experiment_name CWQ_finetune_15_continue 1>./logs/CWQ_finetune_15_continue.log 2>&1 &

# 加载指导部分
# 47.78
CUDA_VISIBLE_DEVICES=0 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder ~/work/QA/KBQA/datasets/CWQ/ --checkpoint_dir ~/work/QA/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_8-h1.ckpt --ckpt_4_pretrain CFQ_2-11.ckpt --finetune_instruction --early_stop_patience 30 --experiment_name CWQ_finetune_10 1>./logs/CWQ_finetune_10.log 2>&1 &
# 48.77
CUDA_VISIBLE_DEVICES=4 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 200 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_8-h1.ckpt --ckpt_4_pretrain CFQ_2-7.ckpt --finetune_instruction --early_stop_patience 30 --experiment_name CWQ_finetune_16 1>./logs/CWQ_finetune_16.log 2>&1 &
#CUDA_VISIBLE_DEVICES=4 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 200 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_8-h1.ckpt --ckpt_4_pretrain CFQ_2-7.ckpt --finetune_instruction --early_stop_patience 30 --continue_training --load_experiment CWQ_finetune_16-h1.ckpt --experiment_name CWQ_finetune_16_continue 1>./logs/CWQ_finetune_16_continue.log 2>&1 &
# 相同学习率大batch 47.01
CUDA_VISIBLE_DEVICES=2 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 1e-3 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_7-h1.ckpt --ckpt_4_pretrain CFQ_2-7.ckpt --finetune --finetune_instruction --early_stop_patience 30 --scheduler_method ExponentialLR --decay_rate 0.97 --experiment_name CWQ_finetune_16_1 1>./logs/CWQ_finetune_16_1.log 2>&1 &
# 不同学习率大batch 45.11
CUDA_VISIBLE_DEVICES=3 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_7-h1.ckpt --ckpt_4_pretrain CFQ_2-7.ckpt --finetune --finetune_instruction --early_stop_patience 30 --merge_lr --fintune_param_lr 1e-4 --scratch_param_lr 1e-3 --scheduler_method ExponentialLR --decay_rate 0.97 --experiment_name CWQ_finetune_16_2 1>./logs/CWQ_finetune_16_2.log 2>&1 &
CUDA_VISIBLE_DEVICES=1 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder ~/work/QA/KBQA/datasets/CWQ/ --checkpoint_dir ~/work/QA/KBQA/checkpoint/ --batch_size 80 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_7-h1.ckpt --ckpt_4_pretrain CFQ_4-5.ckpt --finetune --finetune_instruction --early_stop_patience 25 --merge_lr --fintune_param_lr 1e-4 --scratch_param_lr 1e-3 --scheduler_method ExponentialLR --decay_rate 0.97 --experiment_name CWQ_finetune_18 1>./logs/CWQ_finetune_18.log 2>&1 &

# 46.53
#CUDA_VISIBLE_DEVICES=0 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_8-h1.ckpt --ckpt_4_pretrain CFQ_3-11.ckpt --finetune_instruction --early_stop_patience 30 --experiment_name CWQ_finetune_5 1>./logs/CWQ_finetune_5.log 2>&1 &

#CUDA_VISIBLE_DEVICES=0 python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --encode_type --eps 0.95 --num_epoch 100 --use_self_loop --lr 1e-4 --q_type seq --loss_type kl --reason_kb --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --question_encoder lm --load_experiment CWQ_finetune_1-0.ckpt --is_eval
CUDA_VISIBLE_DEVICES=1 python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --encode_type --eps 0.95 --num_epoch 100 --use_self_loop --lr 1e-4 --q_type seq --loss_type kl --reason_kb --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --question_encoder lm  --lm_name "bert" --load_experiment CWQ_finetune_14-h1.ckpt --is_eval
CUDA_VISIBLE_DEVICES=1 python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 40 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 200 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --load_experiment CWQ_finetune_14-h1.ckpt --is_eval
CUDA_VISIBLE_DEVICES=1 python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 200 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding --reason_with_same_param --load_experiment CWQ_8_1_continue-h1.ckpt --is_eval
CUDA_VISIBLE_DEVICES=1 python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 40 --test_batch_size 80 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 200 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --update_last_lm_layer --relation_emb_file "relations_bert_embedding.npy" --fix_relation_embedding  --load_experiment CWQ_finetune_15_1-h1.ckpt --is_eval




# 使用roberta 46.56
CUDA_VISIBLE_DEVICES=0 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 20 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "roberta" --update_last_lm_layer --relation_emb_file "relations_roberta_mean_embedding.npy" --fix_relation_embedding --early_stop_patience 30 --experiment_name CWQ_10 1>./logs/CWQ_10.log 2>&1 &

#CUDA_VISIBLE_DEVICES=1 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 40 --test_batch_size 40 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 100 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "roberta" --update_last_lm_layer --relation_emb_file "relations_roberta_mean_embedding.npy" --fix_relation_embedding --ckpt_4_embedding CWQ_8-h1.ckpt --ckpt_4_pretrain CFQ_4-5.ckpt --early_stop_patience 30 --experiment_name CWQ_finetune_8 1>./logs/CWQ_finetune_8.log 2>&1 &

# 使用TransE
# 使用dim=50 跑scratch  CWQ_11 46.45
CUDA_VISIBLE_DEVICES=5 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --relation_emb_file "relations_transe_embedding.npy" --fix_relation_embedding --early_stop_patience 25 --filter --experiment_name CWQ_11 1>./logs/CWQ_11.log 2>&1 &
# 不同type进行测试
CUDA_VISIBLE_DEVICES=4 python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/type_group/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --relation_emb_file "relations_transe_embedding.npy" --fix_relation_embedding --early_stop_patience 25 --filter --load_experiment "CWQ_11-h1.ckpt" --is_eval --eval_different_type

# 使用dim=50 bs=128跑scratch CWQ_11_1 45.62
CUDA_VISIBLE_DEVICES=7 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 128 --test_batch_size 128 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 1e-3 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --relation_emb_file "relations_transe_embedding.npy" --fix_relation_embedding --early_stop_patience 25 --filter --experiment_name CWQ_11_1 1>./logs/CWQ_11_1.log 2>&1 &
# 使用cfq-3迁移dim=50的推理部分 CWQ_finetune_22 44.63
CUDA_VISIBLE_DEVICES=4 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --relation_emb_file "relations_transe_embedding.npy" --fix_relation_embedding --early_stop_patience 30 --filter --ckpt_4_embedding CWQ_11-h1.ckpt --ckpt_4_pretrain CFQ_11-3.ckpt --finetune --finetune_reasoning --experiment_name CWQ_finetune_22 1>./logs/CWQ_finetune_22.log 2>&1 &
# 使用cfq-7迁移dim=50的推理部分 CWQ_finetune_23 47.35
CUDA_VISIBLE_DEVICES=0 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --relation_emb_file "relations_transe_embedding.npy" --fix_relation_embedding --early_stop_patience 30 --filter --ckpt_4_embedding CWQ_11-h1.ckpt --ckpt_4_pretrain CFQ_11-7.ckpt --finetune --finetune_reasoning --experiment_name CWQ_finetune_23 1>./logs/CWQ_finetune_23.log 2>&1 &
# 不同type进行测试
CUDA_VISIBLE_DEVICES=4 python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/type_group/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --relation_emb_file "relations_transe_embedding.npy" --fix_relation_embedding --early_stop_patience 25 --filter --load_experiment "CWQ_finetune_23-h1.ckpt" --is_eval --eval_different_type

# 使用cfq-7迁移dim=50的score weight部分 CWQ_finetune_28
CUDA_VISIBLE_DEVICES=3 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --relation_emb_file "relations_transe_embedding.npy" --fix_relation_embedding --early_stop_patience 30 --filter --ckpt_4_embedding CWQ_11-h1.ckpt --ckpt_4_pretrain CFQ_11-7.ckpt --finetune --finetune_gnn --experiment_name CWQ_finetune_28 1>./logs/CWQ_finetune_28.log 2>&1 &
# 使用cfq-7迁移dim=50的gnn weight部分 CWQ_finetune_29
CUDA_VISIBLE_DEVICES=7 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --relation_emb_file "relations_transe_embedding.npy" --fix_relation_embedding --early_stop_patience 30 --filter --ckpt_4_embedding CWQ_11-h1.ckpt --ckpt_4_pretrain CFQ_11-7.ckpt --finetune --finetune_scoring --experiment_name CWQ_finetune_29 1>./logs/CWQ_finetune_29.log 2>&1 &


# 使用dim=50使用bert 跑scratch
CUDA_VISIBLE_DEVICES=0 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder ~/work/QA/KBQA/datasets/CWQ/ --checkpoint_dir ~/work/QA/KBQA/datasets/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --early_stop_patience 25 --filter --experiment_name CWQ_13 1>./logs/CWQ_13.log 2>&1 &
# 只使用bert 迁移
CUDA_VISIBLE_DEVICES=6 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --early_stop_patience 25 --filter --ckpt_4_embedding CWQ_13-h1.ckpt --ckpt_4_pretrain CFQ_13-7.ckpt --finetune --finetune_reasoning --experiment_name CWQ_finetune_30 1>./logs/CWQ_finetune_30.log 2>&1 &
# 使用dim=50使用kge 跑scratch
CUDA_VISIBLE_DEVICES=1 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 50 --word_dim 300 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl  --word_emb_file word_emb_300d.npy --relation_emb_file "relations_transe_embedding.npy" --fix_relation_embedding --early_stop_patience 25 --filter --experiment_name CWQ_14 1>./logs/CWQ_14.log 2>&1 &
# 只使用kge 迁移
CUDA_VISIBLE_DEVICES=4 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 50 --word_dim 300 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl  --word_emb_file word_emb_300d.npy --relation_emb_file "relations_transe_embedding.npy" --fix_relation_embedding --early_stop_patience 25 --filter --ckpt_4_embedding CWQ_14-h1.ckpt --ckpt_4_pretrain CFQ_14-7.ckpt --finetune --finetune_reasoning --experiment_name CWQ_finetune_31 1>./logs/CWQ_finetune_31.log 2>&1 &



# 使用cfq-9迁移dim=50的推理部分 CWQ_finetune_24 45.54
CUDA_VISIBLE_DEVICES=1 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --relation_emb_file "relations_transe_embedding.npy" --fix_relation_embedding --early_stop_patience 30 --filter --ckpt_4_embedding CWQ_11-h1.ckpt --ckpt_4_pretrain CFQ_11-9.ckpt --finetune --finetune_reasoning --experiment_name CWQ_finetune_24 1>./logs/CWQ_finetune_24.log 2>&1 &
# 使用cfq-1迁移dim=50的推理部分 CWQ_finetune_25 45.62
CUDA_VISIBLE_DEVICES=7 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --relation_emb_file "relations_transe_embedding.npy" --fix_relation_embedding --early_stop_patience 30 --filter --ckpt_4_embedding CWQ_11-h1.ckpt --ckpt_4_pretrain CFQ_11-1.ckpt --finetune --finetune_reasoning --experiment_name CWQ_finetune_25 1>./logs/CWQ_finetune_25.log 2>&1 &
# 使用cfq-7迁移dim=50 的问题部分 CWQ_finetune_26
CUDA_VISIBLE_DEVICES=3 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --relation_emb_file "relations_transe_embedding.npy" --fix_relation_embedding --early_stop_patience 30 --filter --ckpt_4_embedding CWQ_11-h1.ckpt --ckpt_4_pretrain CFQ_11-7.ckpt --finetune --finetune_instruction --experiment_name CWQ_finetune_26 1>./logs/CWQ_finetune_26.log 2>&1 &
# 使用cfq-7迁移dim=50 的所有部分 CWQ_finetune_27
CUDA_VISIBLE_DEVICES=7 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 50 --word_dim 768 --kg_dim 100 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --relation_emb_file "relations_transe_embedding.npy" --fix_relation_embedding --early_stop_patience 30 --filter --ckpt_4_embedding CWQ_11-h1.ckpt --ckpt_4_pretrain CFQ_11-7.ckpt --finetune --finetune_whole --experiment_name CWQ_finetune_27 1>./logs/CWQ_finetune_27.log 2>&1 &



# 使用dim=200 跑scratch CWQ_12 49.36
CUDA_VISIBLE_DEVICES=2 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 200 --word_dim 768 --kg_dim 200 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --relation_emb_file "relations_transe_embedding.npy" --fix_relation_embedding --early_stop_patience 25 --filter --experiment_name CWQ_12 1>./logs/CWQ_12.log 2>&1 &
# 使用cfq-3迁移dim=200 的推理部分 CWQ_finetune_19 49.48
CUDA_VISIBLE_DEVICES=0 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 200 --word_dim 768 --kg_dim 200 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --relation_emb_file "relations_transe_embedding.npy" --fix_relation_embedding --early_stop_patience 30 --filter --ckpt_4_embedding CWQ_11-h1.ckpt --ckpt_4_pretrain CFQ_10-3.ckpt --finetune --finetune_reasoning --experiment_name CWQ_finetune_19 1>./logs/CWQ_finetune_19.log 2>&1 &
# 增大学习率 CWQ_finetune_19_1 48.91
CUDA_VISIBLE_DEVICES=0 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 200 --word_dim 768 --kg_dim 200 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 5e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --relation_emb_file "relations_transe_embedding.npy" --fix_relation_embedding --early_stop_patience 30 --filter --ckpt_4_embedding CWQ_11-h1.ckpt --ckpt_4_pretrain CFQ_10-3.ckpt --finetune --finetune_reasoning --experiment_name CWQ_finetune_19_1 1>./logs/CWQ_finetune_19_1.log 2>&1 &
# 使用cfq-3迁移dim=200 的问题部分 CWQ_finetune_20 46.22
CUDA_VISIBLE_DEVICES=1 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 200 --word_dim 768 --kg_dim 200 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --relation_emb_file "relations_transe_embedding.npy" --fix_relation_embedding --early_stop_patience 30 --filter --ckpt_4_embedding CWQ_11-h1.ckpt --ckpt_4_pretrain CFQ_10-3.ckpt --finetune --finetune_instruction --experiment_name CWQ_finetune_20 1>./logs/CWQ_finetune_20.log 2>&1 &
# 使用cfq-3迁移dim=200 的所有部分 CWQ_finetune_21 47.61
CUDA_VISIBLE_DEVICES=7 nohup python main_nsm.py --name CWQ --model_name gnn --data_folder /mnt/jiangjinhao/KBQA/datasets/CWQ/ --checkpoint_dir /mnt/jiangjinhao/KBQA/checkpoint/ --batch_size 80 --test_batch_size 80 --num_step 4 --entity_dim 200 --word_dim 768 --kg_dim 200 --kge_dim 100 --eval_every 2 --eps 0.95 --num_epoch 150 --use_self_loop --lr 1e-4 --q_type seq --reason_kb --encode_type --loss_type kl --question_encoder lm --lm_name "bert" --update_last_lm_layer --relation_emb_file "relations_transe_embedding.npy" --fix_relation_embedding --early_stop_patience 30 --filter --ckpt_4_embedding CWQ_11-h1.ckpt --ckpt_4_pretrain CFQ_10-3.ckpt --finetune --finetune_whole --experiment_name CWQ_finetune_21 1>./logs/CWQ_finetune_21.log 2>&1 &
